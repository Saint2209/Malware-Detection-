#import machine learning essentials
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import mutual_info_classif
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn import model_selection
import seaborn as sns  # Python visualization library based on matplotlib provides a high-level interface for drawing attractive statistical graphics
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import numpy as np  # linear algebra
import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib
import matplotlib.pyplot as plt  # For graphical representation
from sklearn.preprocessing import LabelEncoder

# Import ML modules
sns.set_style('darkgrid')




def correlation_coeffiecient(X_train, y_train):
    #correlation coefficient
    corr_matrix = X_train.corr()
    upper_tri = corr_matrix.where(
        np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))
    #plot correlation matrix
    fig, ax = plt.subplots(figsize=(25, 25))
    sns.heatmap(upper_tri, annot=True, cmap='coolwarm',
                square=True, fmt='.2f', annot_kws={'size': 25})
    plt.show()

    #threshold
    threshold = 0.8

    #drop columns with correlation above threshold
    to_drop = [column for column in upper_tri.columns if any(
        upper_tri[column] > threshold)]
    

    return X_train.drop(labels=to_drop, axis=1)


def stacked_ensemble(X_train, y_train):
    # prepare estimators
    estimators = []
    estimators.append(('RF', RandomForestClassifier()))
    estimators.append(('DT', DecisionTreeClassifier()))
    estimators.append(('NB', GaussianNB()))

    # create the ensemble model
    ensemble = StackingClassifier(
        estimators=estimators, final_estimator=LogisticRegression())

    clf = ensemble.fit(X_train, y_train)

    return clf


def main():

    # Data acquisition: load csv
    df = pd.DataFrame(pd.read_csv('Data/Obfuscated-MalMem2022.csv'))
    # Unlock pandas power (yeah!!!)
    pd.set_option('display.max_rows', 500)
    pd.set_option('display.max_columns', 500)

    # 1.Column Category is unnecessary for this study as we will simply be looking at classifications
    df.drop('Category', axis=1, inplace=True)
    # df.reset_index(drop=True, inplace=True)
    print("dropped Category")

    # Seperating the targets from the features.
    # select all features but target
    X = df.drop('Class', axis=1)
    # select only target
    y = df["Class"]

    #label encode the target variable
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y)  # 0 = benign, 1 = malicious
    

    #drop columns with no standard deviation of 0
    X = df.drop(labels=X.loc[:, X.std() == 0].columns, axis=1)
    #split data into training and testing sets
    X = correlation_coeffiecient(X, y)

    X.head()

    print((X.shape))

    X_train, X_test, y_train, y_test = model_selection.train_test_split(
        X, y, test_size=0.2, random_state=42)

    
    clf = stacked_ensemble(X_train, y_train)

    #make predictions
    y_pred = clf.predict(X_test)

    #evaluate predictions
    print(accuracy_score(y_test, y_pred))
    print(confusion_matrix(y_test, y_pred))
    print(classification_report(y_test, y_pred))


if __name__ == "__main__":
    main()
