{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Import essentials and visualisation stuff\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler,Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns  # Python visualization library based on matplotlib provides a high-level interface for drawing attractive statistical graphics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  # For graphical representation\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import ML modules\n",
    "\n",
    "\n",
    "sns.set_style('darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Data acquisition: load csv\n",
    "a = pd.read_csv('Data/Obfuscated-MalMem2022.csv')\n",
    "df = pd.DataFrame(a)\n",
    "# Unlock pandas power (yeah!!!)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Column Category is unnecessary for this study as we will simply be looking at classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.drop('Category', axis=1, inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "print(\"dropped Category\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating the targets from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# select all features but target\n",
    "X = df.iloc[:, 0:-1]\n",
    "# select only target\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "print(\"Targets and features successfully seperated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Clean dataset and remove colums with std =  0***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#clean dataset and remove std=0\n",
    "X = X.loc[:, (X.std() != 0)]\n",
    "print(\"removed std=0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform eda in order to see the shape of the data and decide what further preprocessing is required.**\n",
    "1. Looking for outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "while (count < X.columns.size):\n",
    "    X.iloc[:, count: count + 5].boxplot()\n",
    "    box = plt.gcf()\n",
    "    box.set_size_inches(15, 15)\n",
    "    plt.show()\n",
    "    count = count + 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#look for outliers using histogram\n",
    "count = 0\n",
    "while (count < X.columns.size):\n",
    "    X.iloc[:, count: count + 5].hist()\n",
    "    box = plt.gcf()\n",
    "    box.set_size_inches(15, 15)\n",
    "    plt.show()\n",
    "    count = count + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "Xcolumns = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Normalising data***\n",
    "*The data needs to be normalised as it is evident from the histogram that the data is not spread out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#Standardise data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(\"Standardised data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=X, columns=Xcolumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "while (count < X.columns.size):\n",
    "    X.iloc[:, count: count + 5].boxplot()\n",
    "    box = plt.gcf()\n",
    "    box.set_size_inches(15, 15)\n",
    "    plt.show()\n",
    "    count = count + 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Scaling***\n",
    "1. Robust scaler: (value = (value – median) / (p75 – p25))As it works best with outlier uses the 75th quartile and the 25th quartile, which is more suited to the standard scaler(value = (value – mean) / stdev) which only looks at the mean. Hence robust scaler is better suited for data with a lot of outliers.\n",
    "\n",
    "!!! We want to get rid of outliers as they skew the data in a certain direction and not giving a fair valuation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#robust scaling\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(\"Robust scaled data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=X, columns=Xcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#look for outliers using plot\n",
    "count = 0\n",
    "while (count < X.columns.size):\n",
    "    X.iloc[:, count: count + 10].boxplot()\n",
    "    box = plt.gcf()\n",
    "    box.set_size_inches(15, 15)\n",
    "    plt.show()\n",
    "    count = count + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#look for outliers using histogram\n",
    "count = 0\n",
    "while (count < X.columns.size):\n",
    "    X.iloc[:, count: count + 5].hist()\n",
    "    box = plt.gcf()\n",
    "    box.set_size_inches(15, 15)\n",
    "    plt.show()\n",
    "    count = count + 5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "X.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# absolute value correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True, fmt='.2f', annot_kws={'size': 25})\n",
    "his = plt.gcf()\n",
    "his.set_size_inches(100, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(upper_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "sns.heatmap(upper_tri, annot=True, cmap='coolwarm', square=True, fmt='.2f', annot_kws={'size': 25})\n",
    "his = plt.gcf()\n",
    "his.set_size_inches(100, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold\n",
    "threshold = 0.7\n",
    "\n",
    "#drop columns with correlation above threshold\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "\n",
    "to_keep = [column for column in upper_tri.columns if any(upper_tri[column] <= threshold)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "sns.heatmap(X.corr().abs(), annot=True, cmap='coolwarm', square=True, fmt='.2f', annot_kws={'size': 25})\n",
    "his = plt.gcf()\n",
    "his.set_size_inches(100, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "VarianceThreshold = VarianceThreshold(threshold=0.0001)\n",
    "VarianceThreshold.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VarianceThreshold.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [column for column in X.columns if column not in X.columns[VarianceThreshold.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "sns.heatmap(X.corr(), annot=True, cmap='coolwarm', square=True, fmt='.2f', annot_kws={'size': 25})\n",
    "his = plt.gcf()\n",
    "his.set_size_inches(100, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.concat([X, y], axis=1)\n",
    "dt.columns = X.columns.tolist() + ['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_csv('Data/Obfuscated-MalMem2022-reprocessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3062dad7d99d5be0d3f003f8126f8335e1145e3be86486f88cf97daaa9051385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
